name: Daily Alphabot Scrape

on:
  schedule:
    - cron: "0 3,4 * * *"   # 03:00 et 04:00 UTC tous les jours
  workflow_dispatch: {}     # lancement manuel (toujours exécute)

permissions:
  contents: write

# Évite seulement les chevauchements (le run le plus récent annule l'ancien)
concurrency:
  group: alphabot-daily
  cancel-in-progress: true

jobs:
  run:
    runs-on: ubuntu-latest
    env:
      TZ: "Europe/Paris"     # pour les logs
      WINDOW_HOURS: "24"     # fenêtre glissante (ex. 24h). Ou commente et mets DAY_TZ si tu préfères.
      # DAY_TZ: "Europe/Paris"  # ⇦ décommente pour filtrer “aujourd'hui” en TZ

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install deps
        run: npm ci || npm install

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Scrape
        run: node scraper.mjs
        env:
          MAX_ROWS: "20"

      - name: List outputs
        if: always()
        run: |
          echo "Contenu du dossier out/ :"
          ls -la out || true
          echo "Dernières lignes du debug :"
          test -f out/debug.log && tail -n 200 out/debug.log || true

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: alphabot-${{ github.run_id }}
          path: out/*
          if-no-files-found: warn
